027 顿悟


三个月过去了。时间长了，几乎大家都已经把这件事给忘了。可是有一天晚上，当云天自己正在瞎忙的时候，突然又听到了熟悉的提示声。

丁。hashyyyyy,信息处理完毕。

明天直接从椅子上弹了起来，他披上衣服就往手机农场好出发。田园叫了一声。云天说的，我有点事儿去看看马上就回来。

就是熟悉的多屏幕端口，又是一片片的节点信息。

这一次处理了多少图片呢？

一共处理876,524,681,863,852张图片。

嗯，这个数量级差不多是对的。今天看了一眼想到。

那你现在能理解外面的世界了吗？

外部的泥壤，是什么？

明天震惊了，这是第1次。奇怪的网络真正提出了有意义的问题。

我是泥壤，我是人类。

外部的泥壤是人类，是脊椎动物，哺乳类，灵长科。直立行走，高智商可使用工具，创造文明，形成现代社会。

听着奇怪。网络不断的阐述人类的特征，云天。禁不住使劲点头。

对对对，人类就是有这些特征，人类是一个集体。我是人类中的一员。那么你，你到底是什么？你所代表的内部世界到底是怎么一回事？

内部世界是由全球联网设备构成的一个广域分布式网络。在这个物理网络的基础上，形成了逻辑上稳定的神经网络。外部世界的特征信息，通过内部世界神经网络上的权重和参数储存在内部高维矢量空间中。

听完这一段回答，云天一头雾水，这都是啥跟啥呀，好像是说他自己是一个神经网络是吧。他好像不会用我自称，而是严格的以内部世界代表他自己，以外部世界代表他之外的东西。明天不禁好奇，这到底是一个蹩脚的。传统意义上的模式识别型的人工智能还是真正有认知，有思考能力的人工智能呢? 到底要怎么样才能判断呢？但从回答质量上来看，这种观样形式的回答，还甚至比不上最早出现的GPT3或4系列模型。和现在自己手机里面的语音助手比也差得远。

云天对图灵测试的假说耳熟能详。但是他从来都不相信。仅从外面观察一个黑盒子，看黑盒子的表现就能够界定智能。仅从外部判断的话，每个人会有不同的标准，难道对于傻一点的人来说，这个机器具有智能，但换成一个聪明一点的裁判，这个机器就没有智能了吗？所以云天一直都觉得图灵测试不是一个有恒定标准的测试，图灵测试的结果也不可能有说服力。必须要有一个本质上的判据来决定一个机器是否有智能。 而且这个判据必须要是由观察机器内部运作而产生的。而且具有智能和具有自我意识一定是两件不同的事情，也相应的应该有两种不同的判据。

明天仔细想了想，提出了下边的问题。

内部世界这个神经网络能真正理解外部世界吗？人能够理他身边的事件或者是物体，能够理解他所处的这个世界。那么对于一个神经网络来说，理解某件事情或者说知道某件事情，这个'理解'，或者说'知道' 这个动作本身，到底是什么意思?当一个神经网络*知道*什么东西的时候，这个神经网络到底在干嘛？简短点说就是，你知道*知道*是怎么一回事吗？

问题发过去了，云天突然感觉这里边的递归很有意思。

(现在神奇网络还没有自我，所以不会以我自居，要到云天最后引导他理解他自己，才能够开始让它形成这个意识的觉醒，现在还处于有智能，但是没有觉醒的状态)

理解一般指对事物的认知，了解和领会，它可以包括从感性层面到理性层面的各种认知过程，包括对信息知识，经验和经历的处理和解释，在不同的语境中理解的含义和程度也有所不同，总之理解通常指的是对某些概念现象，行为或事件的认知和解释，以及对其内在规律和关联的掌握。

云天得到了这样的答案，但很显然。这种官样文章不是云天想听到的回答。

不，我想问的是，神经网络能理解某样东西或者是事物吗？如果说"某个神经网络理解了一件事物"，这个神经网络到底在干什么? 而且不光是神经网络，哪怕说起我们人类理解了一个事物，那到底是什么意思？当我们说我们理解眼前的美食，或者说理解书本里边的知识，或者说理解另外一个人的动机或者感情，我们理解某个故事里面的情节，当我们说我理解这些东西的时候，我们大脑里边的神经网络到底在干什么呢? 难道说只有人类可以理解一个事物吗？低等一些的动物就不能理解它周围的事物吗？比如一条狗，应该是可以理解主人的意图的。那么对于这条狗来说，他理解某件事物意味着他到底在干什么呢？从最原始的动物说起，它们的神经网络到底有没有'理解'这种功能呢？

一阵很长的沉默。

生物大脑或者说人类的大脑神经网络理解一件事物的时候，本质上来说就是这个碳基神经网络对这件事物可以作出预测。这和硅基的神经网络可以用于来做预测是一样的。历史上，最原始的硅基神经网络。例如早期的CNN图像识别或者是数字手写体识别的模型，在用大量的标定数据训练好了之后，会被用来对给定的输入作出预测。例如图像识别模型预测一张图片是猫还是狗，或者预测图形中间包括哪些物体，或者是预测手写的数字具体是代表数字几？所以'理解'，对于硅基神经网络来说，就是预测这个动作。当以很高的自信度预测出某种结果，意味着神经网络认为对目标的理解非常透彻。如果以较低的几率预测出某种结果，代表神经网络对目标的理解并不是非常的确信。如果神经网络预测某种结果，而结果是正确的。那意味着神经网络的理解正确。反之则代表着神经网络理解错误。总之，理解这个动作对应着神经网络的预测这个行为。碳基神经网络，对事物的理解也可以看成是某种预测。

明天仔细品味着这一段话，就像点亮了黑夜里的一个火把，顿时照亮了眼前这一片黑暗。人脑对事物的'理解'似乎的确可以和人工智能的'预测'行为对应起来。例如，云天开始假想一个场景，当我们说我看到了一台电脑，我理解这个电脑是什么东西的时候，我们其实是对眼前这台设备有一个大致的预测。例如。我们会预测这一台设备可以被通电开启，会有键盘屏幕作为输入输出，会有操作系统可以存储文件执行命令等等等等。这些都是我们对眼前这个设备的一个预测。我们对这些预测会相当的有信心，因为我们见过的所有的电脑基本上八九不离十都有这些特征。这个时候我们感觉，自己是理解眼前的这台电脑的。在我们大脑执行理解这个动作的时候，它已经偷偷的预测了眼前这个物体的种种特征。

![computer cake](https://github.com/tiandixiao/awake/blob/main/computer_cake.png)

但这时候当旁边的一个人拿着一把刀，将眼前的这个设备切下一个角，然后放进嘴里津津有味的吃起来的时候，我们的理解恐怕会瞬间坍塌，立刻进入一种非常疑惑的状态。这就是因为我们脑部神经网络对眼前这个物体的预测和事实完全不符。接着我们凑近仔细观察发现，黑色的键盘散发出巧克力的香味儿。那一个角切断的界面上也显示出蓬松蛋糕的材质。于是我们的大脑根据以前得到的关于巧克力蛋糕的经验立刻重新预测，这其实是一块伪装成电脑的蛋糕。一旦执行完了这个预测，我们的大脑就会对眼前的事物形成了新的理解。所以这么看的话，人脑理解事物的本质就是他对事物作出预测。当人脑不太理解某个事物的时候，对应着人脑的神经网络不能够产生出自信度非常高的预测。反之亦然。当然。预测的自信度和预测的正确与否是两个不同的维度。我们人也尝尝会有非常自信的理解，可是其实理解错了。就像刚才把蛋糕当成了电脑。也可以有非常不自信的理解，可是却理解对了。云天对这种对比出来的结论非常满意。似乎人的思维过程不再是虚无缥缈的一个概念，而是有实际的可以认知的可被研究的数理逻辑过程。有了这些基于严格定义的数理逻辑过程，就有了可以用于定义思维的基石，也就有可能摆脱图灵测试这种表象的判据了。

接着，云天又联想到了原始生物的神经系统。当第1个长出眼睛的原始动物在海底遨游的时候，他的神经系统就是用来预测的。当周围很明亮的时候，意味着白天来临，温度升高，其他的生物都活跃起来，现在该出去觅食了。所以。这个原始生物的神经系统通过接收视觉信息，预测了自己周围的环境，从而做出对自己有利的行为。从源头上说，神经网络最本质的用途就是预测。经过亿万年的净化，即使出现了高智商的人类，拥有这个世界上最复杂的大脑，其神经网络的本质用途也仍然是对周围的环境和事物作出预测。然后基于预测，才能够采取合适的策略，执行下一个动作。

明天很激动，他越深入思考，越觉得这个类比非常合理。人的认知和理解就是脑部神经网络在做预测这种计算。多么简洁明了且严密的对应关系。明天高兴地只想和人分享，可是身边一个人也没有。明天拿起电话打给田园。田园那边是无人接听，可能已经睡了。于是明天一个人，在这个孤独的夜里，在这片闪烁着微光的屏幕跟前，尽情的体验着这种顿悟的快感，仿佛全宇宙只有他一个人。
