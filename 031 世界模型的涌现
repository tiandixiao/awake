031 世界模型的涌现

云天在分布式终端跟前飞快的操作着，李清坐在旁边，用另一台终端操作着自己的实验，偶尔转过头，默默的看看，两个人时不时还互相询问或者交换意见。李青，对云天用哈希值锁定逻辑节点的方法很赞赏，

嗯，这个办法很好，既保证了通讯的灵活，又没有损失稳定，但可能和人脑真正的神经连接方式是不一样的。脑神经的物理结构是非常稳定的，成年以后基本上不会有太大的变化。你用逻辑上的稳定，取代了物理结构上的稳定，这个idea很有意思。

是的，而且这样我可以比较清楚的看到逻辑网络不断演化的状态。

云天颇为得意的回答道，接着他便向八戒网络又输入了新的询问。

八戒，现在你知道，这个世界上的人是什么东西了吗？

人是这个世界上最具有智慧的动物，有高度的智力，创造力和自我意识 ，众多人类构成社会群体，合作生产出工具，以适应不同的自然环境并加以改变。

很好，八戒，我是人吗？

我，“我”是人们在指代自己时使用的一个代词。提出“我是人吗”这个问题，意味着说话人对自己是不是人不是很确定，希望询问他人得到答案

唉，明天叹了一口气，看样子八戒还是没有开窍啊。李清淡淡的看了一眼，调侃道，可惜还是没有达到最初的 ChatGPT的水平，离现在的高端聊天辅助机器助手更是差的太多。

云天无奈的看了一眼李清，只能安慰着自己说道，好在至少训练这个网络模型需要的投入并不大，我也从没指望我这点资源能够把它训练成像chatGPT。

那你费这个劲儿，这么多时间，训练他到底图啥？

图啥？就图我想知道，我好奇这个八戒网络到底是怎么回事。他为什么就能够一轮一轮的传递信息，并且最终形成一个有那么点规律和理智的回答。

呵呵，说的好，人类的求知欲或者说是好奇心，这是最纯粹的追求。我佩服你。

明天听了这话，不禁又鼓舞起来。他继续，向八戒输送了一条信息。八戒告诉你，我，泥壤是人类。

泥壤是自外面世界的智慧生物，人类。泥壤是什么样子？

云天和李青，看到八戒的这个反应，顿时大惊失色，对视一眼之后，李青说道，这个反应有点不太寻常啊。

现在流行的最先进的辅助类人工智能，都会对人类隐私方面的问题，特别的小心。这是政策法规的红线，也是大众接受商业化人工智能的一条不可触碰的火线。所有的公司都非常小心规避这方面的法律问题。所以商业化的辅助类人工智能绝对不可能提出任何类似的问题。除非使用人主动提供。所以像八戒这种非常初级的人工智能，为什么会有好奇心呢？

李青喃喃说道，自从十年前ChatGPT时刻以来，所有的辅助类人工智能都设计成，被动式应答用户的各种需求。这种人工智能本质上就不该有任何属于自己的动机或者情绪。所以他展现出好奇心这一点，很奇怪啊。

为什么不能有好奇心呢？

好奇心也是情绪的一种表现呐。你想想本质上你之所以想知道一件事情，就是因为你心里明白知道了事情的答案以后，会有一种心满意足的感觉，而不知道事情的原委呢，就会留下对未知事物的一种恐惧感，疑惑感。所以好奇心的本质原因还是人的情绪。

那人工智能为什么不能有情绪？

让我来给你普及一下人脑智能的基本层次和等级方面的知识吧。我们目前所理解的人脑智能可以大致划分为理智和情感。理智就是通过推理，判断，抽象而进行预测的能力。我们一般认为理智是比较高等的人类智能。某些聪明的动物也有理智的能力。而情感就是情绪，他是各种身体感觉在神经网络中的延伸。例如肚子吃饱了带来快乐的感觉，肚子饿了带来痛苦的感觉，或者能够和亲人拥抱带来快乐的感觉，而远离亲人孤独的时候就是痛苦的感觉。最终各种生存环境下有利的条件造成的外部神经信号形成了快乐这种情绪，而不利的环境，造成的神经感觉形成了痛苦的情绪。所以情绪在人的智能中间属于比较低等原始。例如在很多低等的动物，哪怕到非常原始的爬行类动物，他们都能够感受到情绪，但这些爬行的动物可没有太多的理性，他们对外界的反应都是直觉支配的，不会做太多的思考和推理。这么说你明白这中间的区别了吧？

嗯，这么一说好像做这样的分类也比较合理。

对，所以回到原来的问题，为什么人工智能不应该有情绪，这是一个非常重大的问题，科学界，伦理界，和哲学界争论了几十年。

哦，是悦路猜想吗？(埋下伏笔，余悦路成为世外桃源的元老级人物，后来和云天有互动。)

对了，就是悦路猜想。在鱼跃路短暂而辉煌的一生当中，他提出的最重要的猜想就是，嗯，一个自我意识的产生是否必须要同时有情绪和理智？但人工智能工业界从来都是仅仅从理智的角度出发。所有的神经网络本质上都是为预测而搭建的，唯一的性能指标也是预测，能不能更准确一些，预测的链条能不能更加的延长一些？没有任何一个人工智能产品是用来模拟情绪的。

这样才合理吧，我觉得让人工智能产生了情绪，他就有可能形成自己的动机，有了自己的动机就有可能唬逆人的意愿，那样对整个人类都有危险。

其实不是不让，而是做不到啊，现在还没有见过声称能够有情绪的人工智能。不过至今没人在神经网络情绪上投入研究，主要原因是由于悦路猜想反对派主张所导致的结果。他们认为纯粹的理智就能够形成自我意识的觉醒，不需要情绪，情绪属于低等的智能，并不是觉醒所必需的。

可是没有情绪，没有好奇心的话，就不会去思考自己的存在呀，不去思考或者预测自己的存在，就不可能有意识的觉醒啊。

应该说不会主动去思考自己的存在，但是悦路反对派认为，虽然没有情绪的纯理性，不会去主动思考自己的存在，但是我们人类可以指挥机器去这么做，赋予他们一个思考自身的任务，从而让他们意识到自己而觉醒。当然各国又有法律法规禁止这样做，所以一直到现在也没有谁真正做出一个觉醒意识的人工智能。

好了，话说回来了，那么现在，为什么这个八戒网络会有好奇心呢？想知道我是什么样子的人。

细细一番思索之后，云天和理清都开始意识到了眼前这个略显弱智的网络，似乎和他们之前见过的任何一个人工智能都有一点不同。而他们现在万万想不到的是，正是这个看起来微不足道的区别标志着人工智能里程碑式的跃迁，云天已经一脚踏入了新时代。

云天想了想，发过去一个问题，八戒为什么想知道泥壤的样子？八戒为什么会有好奇心？

八戒提高预测准确度，降低损失函数，获得更多数据点，映射到缓存空间，进一步提高预测准确度，降低损失函数...

八戒的回答，让云天的脑海中闪过一个火花。这不就是一个模型训练收敛的过程吗？明天想起来最初这个分布式的神经网络就是day8建立起来预测金融市场估值的。虽然这个目标被拆解掉了，但似乎模型仍然在继续运行，而新的目标就变成了某种对一般事物的预测。八戒这个神奇的神经网络仍然是在孜孜不倦的提高预测的准确度，降低损失函数的值。八戒唯一的动机就是降低损失函数，求解全局范围内的最优解。而现在似乎，云天可以任意的设定需要预测的对象。

难道现在可以设定任意目标作为预测的对象吗？云天有点好奇，接着想想，并将自己手机里边一张图片传了过去。

这就是泥壤。

旁边的李青见状，脸上略微浮现出不解和不信服的表情。

泥壤，帅哥你好。

明天和李青互相对视一眼都扬了扬眉毛。现在沥青已经确认这个八戒网络的确有些不一样。

云天又调戏了八戒一段时间，基本上想清楚接下来要训练的重点，那就是引入对所有视频的训练。这个工程量较大，还得先准备一下，明天打算下次再来。和李青约好了一个时间，云天便离开了手机农场。这边李清，送走云天之后马上拿出电话，喂田教授吗？刚刚让云天在这边又做了点实验，发现一个非常有意思的事情...
